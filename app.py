import streamlit as st
import requests
import json
import pandas as pd
import time
import concurrent.futures
import re

#######################################
# 1) –ù–ê–°–¢–†–û–ô–ö–ò –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø
#######################################

# –ë–∞–∑–æ–≤—ã–π URL API Novita
API_BASE_URL = "https://api.novita.ai/v3/openai"
LIST_MODELS_ENDPOINT = f"{API_BASE_URL}/models"
CHAT_COMPLETIONS_ENDPOINT = f"{API_BASE_URL}/chat/completions"

# –ö–ª—é—á –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–ù–ï–ë–ï–ó–û–ü–ê–°–ù–û –≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–¥–µ)
DEFAULT_API_KEY = "sk_MyidbhnT9jXzw-YDymhijjY8NF15O0Qy7C36etNTAxE"

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ 429 (Rate Limit)
MAX_RETRIES = 3

# –°–ª–æ–≤–∞—Ä—å –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —è–∑—ã–∫–æ–≤
SOURCE_LANGUAGES = {
    "Auto": "Auto-detect language",
    "English": "English source text",
    "Japanese": "Japanese source text (Êó•Êú¨Ë™û)",
    "Chinese": "Chinese source text (‰∏≠Êñá)",
    "Hindi": "Hindi source text (‡§π‡§ø‡§®‡•ç‡§¶‡•Ä)"
}

TARGET_LANGUAGES = {
    "English": "Translate to English",
    "Japanese": "Translate to Japanese (Êó•Êú¨Ë™û)", 
    "Chinese": "Translate to Chinese (‰∏≠Êñá)",
    "Hindi": "Translate to Hindi (‡§π‡§ø‡§®‡•ç‡§¶‡•Ä)"
}

st.set_page_config(page_title="Novita AI Batch Processor", layout="wide")

#######################################
# 2) –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –§–£–ù–ö–¶–ò–ò
#######################################

def get_language_system_prompt(source_lang: str, target_lang: str, base_prompt: str) -> str:
    """
    Generate system prompt based on source and target languages
    """
    if source_lang == target_lang:
        return base_prompt
    
    language_instructions = {
        ("English", "Japanese"): """
            Translate the following English text to Japanese.
            Rules:
            - Keep names unchanged
            - Preserve technical terms
            - Maintain the original style and tone
            - Ensure natural Japanese expression
        """,
        ("English", "Chinese"): """
            Translate the following English text to Chinese.
            Rules:
            - Keep names unchanged
            - Preserve technical terms
            - Maintain the original style and tone
            - Use appropriate Chinese characters
        """,
        ("English", "Hindi"): """
            Translate the following English text to Hindi.
            Rules:
            - Keep names unchanged
            - Preserve technical terms
            - Maintain the original style and tone
            - Use proper Hindi grammar
        """,
        # Add other language pair combinations here
    }
    
    # Get instructions for the language pair, or generate generic instructions
    pair_key = (source_lang, target_lang)
    if pair_key in language_instructions:
        return f"{base_prompt}\n\n{language_instructions[pair_key]}"
    else:
        return f"{base_prompt}\n\nTranslate from {source_lang} to {target_lang}, keeping names and technical terms unchanged."

def custom_postprocess_text(text: str) -> str:
    """
    –£–±–∏—Ä–∞–µ–º 'fucking' (–≤ –ª—é–±–æ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ) —Ç–æ–ª—å–∫–æ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏.
    –ï—Å–ª–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º.
    """
    pattern_start = re.compile(r'^(fucking\s*)', re.IGNORECASE)
    text = pattern_start.sub('', text)
    return text

def get_model_list(api_key: str):
    """–ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ —ç–Ω–¥–ø–æ–∏–Ω—Ç Novita AI"""
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    try:
        resp = requests.get(LIST_MODELS_ENDPOINT, headers=headers)
        if resp.status_code == 200:
            data = resp.json()
            models = [m["id"] for m in data.get("data", [])]
            return models
        else:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π. –ö–æ–¥: {resp.status_code}. –¢–µ–∫—Å—Ç: {resp.text}")
            return []
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
        return []

def chat_completion_request(
    api_key: str,
    messages: list,
    model: str,
    max_tokens: int,
    temperature: float,
    top_p: float,
    min_p: float,
    top_k: int,
    presence_penalty: float,
    frequency_penalty: float,
    repetition_penalty: float
):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ (–Ω–µ-—Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ–≥–æ) chat-–∫–æ–º–ø–ª–∏—à–µ–Ω–∞ —Å retries –Ω–∞ 429."""
    payload = {
        "model": model,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": temperature,
        "top_p": top_p,
        "top_k": top_k,
        "presence_penalty": presence_penalty,
        "frequency_penalty": frequency_penalty,
        "repetition_penalty": repetition_penalty,
        "min_p": min_p
    }

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }

    attempts = 0
    while attempts < MAX_RETRIES:
        attempts += 1
        try:
            resp = requests.post(CHAT_COMPLETIONS_ENDPOINT, headers=headers, data=json.dumps(payload))
            if resp.status_code == 200:
                data = resp.json()
                return data["choices"][0]["message"].get("content", "")
            elif resp.status_code == 429:
                # rate limit exceeded, –∂–¥–µ–º 2 —Å–µ–∫
                time.sleep(2)
                # –∏ –ø–æ–ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞
                continue
            else:
                return f"–û—à–∏–±–∫–∞: {resp.status_code} - {resp.text}"
        except Exception as e:
            return f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}"
    # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
    return "–û—à–∏–±–∫–∞: –ü—Ä–µ–≤—ã—à–µ–Ω–æ —á–∏—Å–ª–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ 429 RATE_LIMIT."

def process_single_row(
    api_key: str,
    model: str,
    system_prompt: str,
    user_prompt: str,
    row_text: str,
    max_tokens: int,
    temperature: float,
    top_p: float,
    min_p: float,
    top_k: int,
    presence_penalty: float,
    frequency_penalty: float,
    repetition_penalty: float
):
    """–§—É–Ω–∫—Ü–∏—è-–æ–±—ë—Ä—Ç–∫–∞ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞."""
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"{user_prompt}\n{row_text}"}
    ]
    raw_response = chat_completion_request(
        api_key,
        messages,
        model,
        max_tokens,
        temperature,
        top_p,
        min_p,
        top_k,
        presence_penalty,
        frequency_penalty,
        repetition_penalty
    )

    # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞: —É–±–∏—Ä–∞–µ–º banned words
    final_response = custom_postprocess_text(raw_response)
    return final_response

def process_file(
    api_key: str,
    model: str,
    system_prompt: str,
    user_prompt: str,
    df: pd.DataFrame,
    title_col: str,  # –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—É—é –Ω–∞–¥–æ –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å
    response_format: str,
    max_tokens: int,
    temperature: float,
    top_p: float,
    min_p: float,
    top_k: int,
    presence_penalty: float,
    frequency_penalty: float,
    repetition_penalty: float,
    chunk_size: int = 10,  # —Ñ–∏–∫—Å–∏—Ä—É–µ–º 10 —Å—Ç—Ä–æ–∫ –≤ —á–∞–Ω–∫–µ
    max_workers: int = 5  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤
):
    """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø–æ—Å—Ç—Ä–æ—á–Ω–æ (–∏–ª–∏ —á–∞–Ω–∫–∞–º–∏)."""

    progress_bar = st.progress(0)
    time_placeholder = st.empty()  # –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Å—Ç–∞–≤—à–µ–≥–æ—Å—è –≤—Ä–µ–º–µ–Ω–∏

    results = []
    total_rows = len(df)

    start_time = time.time()
    lines_processed = 0

    for start_idx in range(0, total_rows, chunk_size):
        chunk_start_time = time.time()
        end_idx = min(start_idx + chunk_size, total_rows)

        # –ë–µ—Ä—ë–º –∏–Ω–¥–µ–∫—Å—ã —Å—Ç—Ä–æ–∫ –≤ —ç—Ç–æ–º —á–∞–Ω–∫–µ
        chunk_indices = list(df.index[range(start_idx, end_idx)])
        chunk_size_actual = len(chunk_indices)
        chunk_results = [None] * chunk_size_actual

        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_i = {}
            for i, row_idx in enumerate(chunk_indices):
                row_text = str(df.loc[row_idx, title_col])
                future = executor.submit(
                    process_single_row,
                    api_key,
                    model,
                    system_prompt,
                    user_prompt,
                    row_text,
                    max_tokens,
                    temperature,
                    top_p,
                    min_p,
                    top_k,
                    presence_penalty,
                    frequency_penalty,
                    repetition_penalty
                )
                future_to_i[future] = i

            for future in concurrent.futures.as_completed(future_to_i):
                i = future_to_i[future]
                chunk_results[i] = future.result()

        # –†–∞—Å—à–∏—Ä—è–µ–º –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results.extend(chunk_results)

        lines_processed += chunk_size_actual
        progress_bar.progress(lines_processed / total_rows)

        time_for_chunk = time.time() - chunk_start_time
        if chunk_size_actual > 0:
            time_per_line = time_for_chunk / chunk_size_actual
            lines_left = total_rows - lines_processed
            if time_per_line > 0:
                est_time_left_sec = lines_left * time_per_line
                if est_time_left_sec < 60:
                    time_text = f"~{est_time_left_sec:.1f} —Å–µ–∫."
                else:
                    est_time_left_min = est_time_left_sec / 60.0
                    time_text = f"~{est_time_left_min:.1f} –º–∏–Ω."
                time_placeholder.info(f"–ü—Ä–∏–º–µ—Ä–Ω–æ–µ –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è: {time_text}")

    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é df —Å –Ω–æ–≤—ã–º —Å—Ç–æ–ª–±—Ü–æ–º
    df_out = df.copy()
    df_out["rewrite"] = results

    elapsed = time.time() - start_time
    time_placeholder.success(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed:.1f} —Å–µ–∫—É–Ω–¥.")

    return df_out

#######################################
# 4) –ò–ù–¢–ï–†–§–ï–ô–°
#######################################

st.title("üß† Novita AI Batch Processing")

# –¢—Ä–∏ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ª—É—á—à–µ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
left_col, middle_col, right_col = st.columns([1, 1, 1])

########################################
# –õ–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞: –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏ —è–∑—ã–∫
########################################
with left_col:
    st.markdown("#### –ú–æ–¥–µ–ª–∏ –∏ —è–∑—ã–∫")
    st.caption("–°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–∑ API Novita AI")

    api_key = st.text_input("API Key", value=DEFAULT_API_KEY, type="password")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã–±–æ—Ä —è–∑—ã–∫–∞
    source_language = st.selectbox(
    "Source Language",
    options=list(SOURCE_LANGUAGES.keys()),
    format_func=lambda x: SOURCE_LANGUAGES[x]
)

target_language = st.selectbox(
    "Target Language",
    options=list(TARGET_LANGUAGES.keys()),
    format_func=lambda x: TARGET_LANGUAGES[x]
)

if st.button("–û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π"):
        if not api_key:
            st.error("–ö–ª—é—á API –ø—É—Å—Ç")
            model_list = []
        else:
            model_list = get_model_list(api_key)
            st.session_state["model_list"] = model_list

if "model_list" not in st.session_state:
        st.session_state["model_list"] = []

if len(st.session_state["model_list"]) > 0:
        selected_model = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å", st.session_state["model_list"])
else:
        selected_model = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å",
            ["meta-llama/llama-3.1-8b-instruct", "Nous-Hermes-2-Mixtral-8x7B-DPO"]
        )

########################################
# –°—Ä–µ–¥–Ω—è—è –∫–æ–ª–æ–Ω–∫–∞: –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
########################################
with middle_col:
    st.markdown("#### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
    output_format = st.selectbox("Output Format", ["csv", "txt"])
    system_prompt = st.text_area("System Prompt", value="Act like you are a helpful assistant.")

########################################
# –ü—Ä–∞–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
########################################
with right_col:
    st.markdown("#### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
    max_tokens = st.slider("max_tokens", min_value=0, max_value=64000, value=512, step=1)
    temperature = st.slider("temperature", min_value=0.0, max_value=2.0, value=0.7, step=0.01)
    top_p = st.slider("top_p", min_value=0.0, max_value=1.0, value=1.0, step=0.01)
    min_p = st.slider("min_p", min_value=0.0, max_value=1.0, value=0.0, step=0.01)
    top_k = st.slider("top_k", min_value=0, max_value=100, value=40, step=1)
    presence_penalty = st.slider("presence_penalty", min_value=0.0, max_value=2.0, value=0.0, step=0.01)
    frequency_penalty = st.slider("frequency_penalty", min_value=0.0, max_value=2.0, value=0.0, step=0.01)
    repetition_penalty = st.slider("repetition_penalty", min_value=0.0, max_value=2.0, value=1.0, step=0.01)

# –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å–Ω–∞—è –ª–∏–Ω–∏—è
st.markdown("---")

########################################
# –ü–æ–ª–µ –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
########################################
st.subheader("–û–¥–∏–Ω–æ—á–Ω—ã–π –ø—Ä–æ–º–ø—Ç")
user_prompt_single = st.text_area("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")

if st.button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å –æ–¥–∏–Ω–æ—á–Ω—ã–π –ø—Ä–æ–º–ø—Ç"):
    if not api_key:
        st.error("API Key –Ω–µ —É–∫–∞–∑–∞–Ω!")
    else:
        from_text = [
            {"role": "system", "content": get_language_system_prompt(target_language, system_prompt)},
            {"role": "user", "content": user_prompt_single}
        ]
        st.info("–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å...")
        raw_response = chat_completion_request(
            api_key=api_key,
            messages=from_text,
            model=selected_model,
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            min_p=min_p,
            top_k=top_k,
            presence_penalty=presence_penalty,
            frequency_penalty=frequency_penalty,
            repetition_penalty=repetition_penalty
        )
        final_response = custom_postprocess_text(raw_response)
        st.success("–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—É—á–µ–Ω!")
        st.text_area("–û—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏", value=final_response, height=200)

# –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å–Ω–∞—è –ª–∏–Ω–∏—è
st.markdown("---")

########################################
# –ë–ª–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞
########################################
st.subheader("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞")

user_prompt = st.text_area("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –∫ –∑–∞–≥–æ–ª–æ–≤–∫—É)")

st.markdown("##### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ TXT/CSV")
delimiter_input = st.text_input("–†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å (delimiter)", value="|")
column_input = st.text_input("–ù–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)", value="id,title")

uploaded_file = st.file_uploader("–ü—Ä–∏–∫—Ä–µ–ø–∏—Ç—å —Ñ–∞–π–ª (CSV –∏–ª–∏ TXT, –¥–æ 100000 —Å—Ç—Ä–æ–∫)", type=["csv", "txt"])

df = None
if uploaded_file is not None:
    file_extension = uploaded_file.name.split(".")[-1]
    try:
        if file_extension == "csv":
            df = pd.read_csv(uploaded_file)
        else:
            content = uploaded_file.read().decode("utf-8")
            lines = content.splitlines()

            columns = [c.strip() for c in column_input.split(",")]

            parsed_lines = []
            for line in lines:
                splitted = line.split(delimiter_input, maxsplit=len(columns) - 1)
                parsed_lines.append(splitted)

            df = pd.DataFrame(parsed_lines, columns=columns)

        st.write("### –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Ñ–∞–π–ª–∞")
        st.dataframe(df.head())
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        df = None

if df is not None:
    cols = df.columns.tolist()
    title_col = st.selectbox("–ö–∞–∫–∞—è –∫–æ–ª–æ–Ω–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–º?", cols)

    # –ü–æ–ª–∑—É–Ω–æ–∫ –¥–ª—è –≤—ã–±–æ—Ä–∞ –∫–æ–ª-–≤–∞ –ø–æ—Ç–æ–∫–æ–≤
    max_workers = st.slider("–ü–æ—Ç–æ–∫–∏ (max_workers)", min_value=1, max_value=20, value=5)

    if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–∞"):
        if not api_key:
            st.error("API Key –Ω–µ —É–∫–∞–∑–∞–Ω!")
        else:
            row_count = len(df)
            if row_count > 100000:
                st.warning(f"–§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç {row_count} —Å—Ç—Ä–æ–∫. –≠—Ç–æ –ø—Ä–µ–≤—ã—à–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–π –ª–∏–º–∏—Ç –≤ 100000.")
            st.info("–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ –ø–æ–¥–æ–∂–¥–∏—Ç–µ...")

            df_out = process_file(
                api_key=api_key,
                model=selected_model,
                system_prompt=get_language_system_prompt(source_language, target_language, system_prompt),
                user_prompt=user_prompt,
                df=df,
                title_col=title_col,
                response_format="csv",
                max_tokens=max_tokens,
                temperature=temperature,
                top_p=top_p,
                min_p=min_p,
                top_k=top_k,
                presence_penalty=presence_penalty,
                frequency_penalty=frequency_penalty,
                repetition_penalty=repetition_penalty,
                chunk_size=10,
                max_workers=max_workers
            )

            st.success("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

            # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ
            if output_format == "csv":
                csv_out = df_out.to_csv(index=False).encode("utf-8")
                st.download_button("–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç (CSV)", data=csv_out, file_name="result.csv", mime="text/csv")
            else:
                txt_out = df_out.to_csv(index=False, sep="|", header=False).encode("utf-8")
                st.download_button("–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç (TXT)", data=txt_out, file_name="result.txt", mime="text/plain")

            st.write("### –õ–æ–≥–∏")
            st.write("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞, —Å—Ç—Ä–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ:", len(df_out))
