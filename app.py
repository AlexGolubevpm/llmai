import streamlit as st
import requests
import json
import pandas as pd
import time
import concurrent.futures
import re

#######################################
# 1) –ù–ê–°–¢–†–û–ô–ö–ò –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø
#######################################

# –ë–∞–∑–æ–≤—ã–π URL API Novita
API_BASE_URL = "https://api.novita.ai/v3/openai"
LIST_MODELS_ENDPOINT = f"{API_BASE_URL}/models"
CHAT_COMPLETIONS_ENDPOINT = f"{API_BASE_URL}/chat/completions"

# –ö–ª—é—á –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–ù–ï–ë–ï–ó–û–ü–ê–°–ù–û –≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–¥–µ)
DEFAULT_API_KEY = "sk_MyidbhnT9jXzw-YDymhijjY8NF15O0Qy7C36etNTAxE"

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ 429 (Rate Limit)
MAX_RETRIES = 3

# –Ø–∑—ã–∫–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
SOURCE_LANGUAGES = {
    "Auto": "Auto-detect language",
    "English": "English source text",
    "Japanese": "Japanese source text (Êó•Êú¨Ë™û)",
    "Chinese": "Chinese source text (‰∏≠Êñá)",
    "Hindi": "Hindi source text (‡§π‡§ø‡§®‡•ç‡§¶‡•Ä)"
}

TARGET_LANGUAGES = {
    "English": "Translate to English",
    "Japanese": "Translate to Japanese (Êó•Êú¨Ë™û)",
    "Chinese": "Translate to Chinese (‰∏≠Êñá)",
    "Hindi": "Translate to Hindi (‡§π‡§ø‡§®‡•ç‡§¶‡•Ä)"
}

st.set_page_config(page_title="Novita AI Translation", layout="wide")

#######################################
# 2) –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
#######################################

def detect_primary_language(text: str) -> str:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞ –ø–æ –±–∞–∑–æ–≤—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º
    """
    japanese_chars = len([c for c in text if '\u4e00' <= c <= '\u9fff' or '\u3040' <= c <= '\u309f'])
    chinese_chars = len([c for c in text if '\u4e00' <= c <= '\u9fff'])
    english_chars = len([c for c in text if ord('a') <= ord(c.lower()) <= ord('z')])
    
    if japanese_chars > len(text) * 0.3:
        return "Japanese"
    elif chinese_chars > len(text) * 0.3:
        return "Chinese"
    elif english_chars > len(text) * 0.3:
        return "English"
    return "Auto"

def get_language_system_prompt(source_lang: str, target_lang: str, base_prompt: str) -> str:
    """
    Enhanced system prompt generator with better mixed language handling
    """
    if source_lang == target_lang:
        return base_prompt
    
    base_rules = """
    Translation Rules:
    1. Preserve all names exactly as they appear
    2. Keep technical terms intact
    3. Maintain the original tone and style
    4. Handle mixed language content appropriately
    5. Ensure consistent translation of repeated phrases
    """
    
    language_specific = {
        ("Auto", "Chinese"): """
            Â∞ÜÊâÄÊúâÊñáÊú¨ÁøªËØëÊàê‰∏≠ÊñáÔºö
            - ‰øùÊåÅ‰∫∫Âêç‰∏çÂèò
            - ‰øùÊåÅÊäÄÊúØÊúØËØ≠‰∏çÂèò
            - ÂØπ‰∫éÊ∑∑ÂêàËØ≠Ë®ÄÊñáÊú¨ÔºåÂ∞ÜÈùû‰∏≠ÊñáÈÉ®ÂàÜÁøªËØëÊàê‰∏≠Êñá
            - ‰øùÊåÅÂéüÊñáÁöÑËØ≠Ê∞îÂíåÈ£éÊ†º
            - ‰ΩøÁî®Ëá™ÁÑ∂ÁöÑ‰∏≠ÊñáË°®Ëææ
            - ÂØπ‰∫éÊàê‰∫∫ÂÜÖÂÆπÔºå‰ΩøÁî®ÈÄÇÂΩìÂßîÂ©âÁöÑË°®ËææÊñπÂºè
        """,
        ("Auto", "Japanese"): """
            „Åô„Åπ„Å¶„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„ÇíÊó•Êú¨Ë™û„Å´ÁøªË®≥Ôºö
            - ‰∫∫Âêç„ÅØ„Åù„ÅÆ„Åæ„Åæ‰øùÊåÅ
            - ÊäÄË°ìÁî®Ë™û„ÅØ„Åù„ÅÆ„Åæ„Åæ‰øùÊåÅ
            - Ê∑∑ÂêàË®ÄË™û„ÉÜ„Ç≠„Çπ„Éà„ÅÆÂ†¥Âêà„ÄÅÊó•Êú¨Ë™û‰ª•Â§ñ„ÅÆÈÉ®ÂàÜ„ÇíÁøªË®≥
            - ÂéüÊñá„ÅÆ„Éà„Éº„É≥„Å®„Çπ„Çø„Ç§„É´„ÇíÁ∂≠ÊåÅ
            - Ëá™ÁÑ∂„Å™Êó•Êú¨Ë™ûË°®Áèæ„Çí‰ΩøÁî®
            - „Ç¢„ÉÄ„É´„Éà„Ç≥„É≥„ÉÜ„É≥„ÉÑ„Å´„ÅØÈÅ©Âàá„Å™Â©âÊõ≤Ë°®Áèæ„Çí‰ΩøÁî®
        """,
        ("Auto", "English"): """
            Translate all text to English:
            - Keep personal names unchanged
            - Preserve technical terms
            - For mixed language text, translate non-English parts
            - Maintain original tone and style
            - Use natural English expressions
            - Use appropriate euphemisms for adult content
        """,
        ("English", "Chinese"): """
            Identify English text and translate to Chinese:
            - Keep all names in original form
            - Preserve technical terms
            - Translate only confirmed English parts
            - Use natural Chinese expressions
            - For adult content, use appropriate Chinese terms
        """,
        ("Japanese", "English"): """
            Identify Japanese text and translate to English:
            - Keep Japanese names in original form
            - Preserve technical terms
            - Translate only confirmed Japanese parts
            - Use natural English expressions
            - For adult content, use appropriate English terms
        """
    }
    
    mixed_language_handling = """
    Mixed Language Handling:
    1. Identify the primary language in each segment
    2. Preserve any intentionally mixed language elements
    3. Translate only the parts that match the source language
    4. Keep formatting and structure intact
    5. Handle adult content appropriately in target language
    """
    
    pair_key = (source_lang, target_lang)
    specific_instructions = language_specific.get(pair_key, "")
    
    full_prompt = f"""
    {base_prompt}
    
    {base_rules}
    
    {specific_instructions}
    
    {mixed_language_handling}
    
    Current translation direction: {source_lang} ‚Üí {target_lang}
    """
    
    return full_prompt

def custom_postprocess_text(text: str) -> str:
    """
    –£–±–∏—Ä–∞–µ–º 'fucking' (–≤ –ª—é–±–æ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ) —Ç–æ–ª—å–∫–æ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏.
    """
    pattern_start = re.compile(r'^(fucking\s*)', re.IGNORECASE)
    text = pattern_start.sub('', text)
    return text

def get_model_list(api_key: str):
    """–ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ —ç–Ω–¥–ø–æ–∏–Ω—Ç Novita AI"""
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    try:
        resp = requests.get(LIST_MODELS_ENDPOINT, headers=headers)
        if resp.status_code == 200:
            data = resp.json()
            models = [m["id"] for m in data.get("data", [])]
            return models
        else:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π. –ö–æ–¥: {resp.status_code}. –¢–µ–∫—Å—Ç: {resp.text}")
            return []
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
        return []

def chat_completion_request(
    api_key: str,
    messages: list,
    model: str,
    max_tokens: int,
    temperature: float,
    top_p: float,
    min_p: float,
    top_k: int,
    presence_penalty: float,
    frequency_penalty: float,
    repetition_penalty: float
):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ (–Ω–µ-—Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ–≥–æ) chat-–∫–æ–º–ø–ª–∏—à–µ–Ω–∞ —Å retries –Ω–∞ 429."""
    payload = {
        "model": model,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": temperature,
        "top_p": top_p,
        "top_k": top_k,
        "presence_penalty": presence_penalty,
        "frequency_penalty": frequency_penalty,
        "repetition_penalty": repetition_penalty,
        "min_p": min_p
    }

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }

    attempts = 0
    while attempts < MAX_RETRIES:
        attempts += 1
        try:
            resp = requests.post(CHAT_COMPLETIONS_ENDPOINT, headers=headers, data=json.dumps(payload))
            if resp.status_code == 200:
                data = resp.json()
                return data["choices"][0]["message"].get("content", "")
            elif resp.status_code == 429:
                time.sleep(2)
                continue
            else:
                return f"–û—à–∏–±–∫–∞: {resp.status_code} - {resp.text}"
        except Exception as e:
            return f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}"
    return "–û—à–∏–±–∫–∞: –ü—Ä–µ–≤—ã—à–µ–Ω–æ —á–∏—Å–ª–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ 429 RATE_LIMIT."

def process_single_row(
    api_key: str,
    model: str,
    system_prompt: str,
    user_prompt: str,
    row_text: str,
    source_lang: str,
    target_lang: str,
    max_tokens: int,
    temperature: float,
    top_p: float,
    min_p: float,
    top_k: int,
    presence_penalty: float,
    frequency_penalty: float,
    repetition_penalty: float
):
    """–û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —è–∑—ã–∫–æ–≤"""
    if source_lang == "Auto":
        detected_lang = detect_primary_language(row_text)
        actual_source = detected_lang
    else:
        actual_source = source_lang

    final_prompt = get_language_system_prompt(actual_source, target_lang, system_prompt)
    
    messages = [
        {"role": "system", "content": final_prompt},
        {"role": "user", "content": f"{user_prompt}\n{row_text}"}
    ]
    
    raw_response = chat_completion_request(
        api_key,
        messages,
        model,
        max_tokens,
        temperature,
        top_p,
        min_p,
        top_k,
        presence_penalty,
        frequency_penalty,
        repetition_penalty
    )

    return custom_postprocess_text(raw_response)

def process_file(
    api_key: str,
    model: str,
    system_prompt: str,
    user_prompt: str,
    df: pd.DataFrame,
    title_col: str,
    source_lang: str,
    target_lang: str,
    response_format: str,
    max_tokens: int,
    temperature: float,
    top_p: float,
    min_p: float,
    top_k: int,
    presence_penalty: float,
    frequency_penalty: float,
    repetition_penalty: float,
    chunk_size: int = 10,
    max_workers: int = 5
):
    """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø–æ—Å—Ç—Ä–æ—á–Ω–æ (–∏–ª–∏ —á–∞–Ω–∫–∞–º–∏)."""

    progress_bar = st.progress(0)
    time_placeholder = st.empty()

    results = []
    total_rows = len(df)

    start_time = time.time()
    lines_processed = 0

    for start_idx in range(0, total_rows, chunk_size):
        chunk_start_time = time.time()
        end_idx = min(start_idx + chunk_size, total_rows)

        chunk_indices = list(df.index[range(start_idx, end_idx)])
        chunk_size_actual = len(chunk_indices)
        chunk_results = [None] * chunk_size_actual

        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_i = {}
            for i, row_idx in enumerate(chunk_indices):
                row_text = str(df.loc[row_idx, title_col])
                future = executor.submit(
                    process_single_row,
                    api_key,
                    model,
                    system_prompt,
                    user_prompt,
                    row_text,
                    source_lang,
                    target_lang,
                    max_tokens,
                    temperature,
                    top_p,
                    min_p,
                    top_k,
                    presence_penalty,
                    frequency_penalty,
                    repetition_penalty
                )
                future_to_i[future] = i

            for future in concurrent.futures.as_completed(future_to_i):
                i = future_to_i[future]
                chunk_results[i] = future.result()

        results.extend(chunk_results)

        lines_processed += chunk_size_actual
        progress_bar.progress(lines_processed / total_rows)

        time_for_chunk = time.time() - chunk_start_time
        if chunk_size_actual > 0:
            time_per_line = time_for_chunk / chunk_size_actual
            lines_left = total_rows - lines_processed
            if time_per_line > 0:
                est_time_left_sec = lines_left * time_per_line
                if est_time_left_sec < 60:
                    time_text = f"~{est_time_left_sec:.1f} —Å–µ–∫."
                else:
                    est_time_left_min = est_time_left_sec / 60.0
                    time_text = f"~{est_time_left_min:.1f} –º–∏–Ω."
                time_placeholder.info(f"–ü—Ä–∏–º–µ—Ä–Ω–æ–µ –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è: {time_text}")

    df_out = df.copy()
    df_out["translation"] = results

    elapsed = time.time() - start_time
    time_placeholder.success(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed:.1f} —Å–µ–∫—É–Ω–¥.")

    return df_out

#######################################
# 4) –ò–ù–¢–ï–†–§–ï–ô–°
#######################################

st.title("üåé Novita AI Batch Translation")

# –¢—Ä–∏ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ª—É—á—à–µ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
left_col, middle_col, right_col = st.columns([1, 1, 1])

########################################
# –õ–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞: –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
########################################
with left_col:
    st.markdown("#### Model Selection")
    st.caption("Models are loaded from Novita AI API")

    api_key = st.text_input("API Key", value=DEFAULT_API_KEY, type="password")

    if st.button("Update Model List"):
        if not api_key:
            st.error("API Key is empty")
            model_list = []
        else:
            model_list = get_model_list(api_key)
            st.session_state["model_list"] = model_list

    if "model_list" not in st.session_state:
        st.session_state["model_list"] = []

    if len(st.session_state["model_list"]) > 0:
        selected_model = st.selectbox("Select Model", st.session_state["model_list"])
    else:
        selected_model = st.selectbox(
            "Select Model",
            ["meta-llama/llama-3.1-8b-instruct", "Nous-Hermes-2-Mixtral-8x7B-DPO"]
        )

########################################
# –°—Ä–µ–¥–Ω—è—è –∫–æ–ª–æ–Ω–∫–∞: –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
########################################
with middle_col:
    st.markdown("#### Generation Parameters")
    output_format = st.selectbox("Output Format", ["csv", "txt"])
    system_prompt = st.text_area(
        "System Prompt", 
        value="You are a professional translator. Translate the following text while preserving names, terms and maintaining the original style."
    )

########################################
# –ü—Ä–∞–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
########################################
with right_col:
    st.markdown("#### Additional Parameters")
    max_tokens = st.slider("max_tokens", min_value=0, max_value=64000, value=512, step=1)
    temperature = st.slider("temperature", min_value=0.0, max_value=2.0, value=0.7, step=0.01)
    top_p = st.slider("top_p", min_value=0.0, max_value=1.0, value=1.0, step=0.01)
    min_p = st.slider("min_p", min_value=0.0, max_value=1.0, value=0.0, step=0.01)
    top_k = st.slider("top_k", min_value=0, max_value=100, value=40, step=1)
    presence_penalty = st.slider("presence_penalty", min_value=0.0, max_value=2.0, value=0.0, step=0.01)
    frequency_penalty = st.slider("frequency_penalty", min_value=0.0, max_value=2.0, value=0.0, step=0.01)
    repetition_penalty = st.slider("repetition_penalty", min_value=0.0, max_value=2.0, value=1.0, step=0.01)

# –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å–Ω–∞—è –ª–∏–Ω–∏—è
st.markdown("---")

########################################
# –ë–ª–æ–∫ –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞
########################################
st.subheader("Single Text Translation")
user_prompt_single = st.text_area("Enter text to translate")

# –í—ã–±–æ—Ä —è–∑—ã–∫–æ–≤ –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞
single_source_lang = st.selectbox(
    "Source Language",
    options=list(SOURCE_LANGUAGES.keys()),
    format_func=lambda x: SOURCE_LANGUAGES[x],
    key="single_source"
)

single_target_lang = st.selectbox(
    "Target Language",
    options=list(TARGET_LANGUAGES.keys()),
    format_func=lambda x: TARGET_LANGUAGES[x],
    key="single_target"
)

if st.button("Translate Single Text"):
    if not api_key:
        st.error("API Key is missing!")
    else:
        final_prompt = get_language_system_prompt(single_source_lang, single_target_lang, system_prompt)
        from_text = [
            {"role": "system", "content": final_prompt},
            {"role": "user", "content": user_prompt_single}
        ]
        st.info("Sending request...")
        raw_response = chat_completion_request(
            api_key=api_key,
            messages=from_text,
            model=selected_model,
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            min_p=min_p,
            top_k=top_k,
            presence_penalty=presence_penalty,
            frequency_penalty=frequency_penalty,
            repetition_penalty=repetition_penalty
        )
        final_response = custom_postprocess_text(raw_response)
        st.success("Translation complete!")
        st.text_area("Translated Text", value=final_response, height=200)

# –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å–Ω–∞—è –ª–∏–Ω–∏—è
st.markdown("---")

########################################
# –ë–ª–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞
########################################
st.subheader("Batch File Translation")

user_prompt = st.text_area("Additional translation instructions (optional)")

st.markdown("##### File Parsing Settings")
delimiter_input = st.text_input("Delimiter", value="|")
column_input = st.text_input("Column names (comma-separated)", value="id,title")

uploaded_file = st.file_uploader("Upload file (CSV or TXT, up to 100000 lines)", type=["csv", "txt"])

# –í—ã–±–æ—Ä —è–∑—ã–∫–æ–≤ –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞
batch_source_lang = st.selectbox(
    "Source Language for Batch Translation",
    options=list(SOURCE_LANGUAGES.keys()),
    format_func=lambda x: SOURCE_LANGUAGES[x],
    key="batch_source"
)

batch_target_lang = st.selectbox(
    "Target Language for Batch Translation",
    options=list(TARGET_LANGUAGES.keys()),
    format_func=lambda x: TARGET_LANGUAGES[x],
    key="batch_target"
)

df = None
if uploaded_file is not None:
    file_extension = uploaded_file.name.split(".")[-1]
    try:
        if file_extension == "csv":
            df = pd.read_csv(uploaded_file)
        else:
            content = uploaded_file.read().decode("utf-8")
            lines = content.splitlines()

            columns = [c.strip() for c in column_input.split(",")]

            parsed_lines = []
            for line in lines:
                splitted = line.split(delimiter_input, maxsplit=len(columns) - 1)
                parsed_lines.append(splitted)

            df = pd.DataFrame(parsed_lines, columns=columns)

        st.write("### File Preview")
        st.dataframe(df.head())
    except Exception as e:
        st.error(f"Error reading file: {e}")
        df = None

if df is not None:
    cols = df.columns.tolist()
    title_col = st.selectbox("Which column contains text to translate?", cols)

    max_workers = st.slider("Threads (max_workers)", min_value=1, max_value=20, value=5)

    if st.button("Start Batch Translation"):
        if not api_key:
            st.error("API Key is missing!")
        else:
            row_count = len(df)
            if row_count > 100000:
                st.warning(f"File contains {row_count} rows. This exceeds the recommended limit of 100000.")
            st.info("Starting translation, please wait...")

            df_out = process_file(
                api_key=api_key,
                model=selected_model,
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                df=df,
                title_col=title_col,
                source_lang=batch_source_lang,
                target_lang=batch_target_lang,
                response_format=output_format,
                max_tokens=max_tokens,
                temperature=temperature,
                top_p=top_p,
                min_p=min_p,
                top_k=top_k,
                presence_penalty=presence_penalty,
                frequency_penalty=frequency_penalty,
                repetition_penalty=repetition_penalty,
                chunk_size=10,
                max_workers=max_workers
            )

            st.success("Translation complete!")

            # Download options
            if output_format == "csv":
                csv_out = df_out.to_csv(index=False).encode("utf-8")
                st.download_button("Download Result (CSV)", data=csv_out, file_name="translations.csv", mime="text/csv")
            else:
                txt_out = df_out.to_csv(index=False, sep="|", header=False).encode("utf-8")
                st.download_button("Download Result (TXT)", data=txt_out, file_name="translations.txt", mime="text/plain")

            st.write("### Results")
            st.write("Processing completed, rows processed:", len(df_out))
