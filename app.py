import streamlit as st
import streamlit.components.v1 as components
import requests
import json
import pandas as pd
import time
import concurrent.futures
import re
import math

#######################################
# 1) –ù–ê–°–¢–†–û–ô–ö–ò –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø
#######################################

# –ë–∞–∑–æ–≤—ã–π URL API Novita
API_BASE_URL = "https://api.novita.ai/v3/openai"
LIST_MODELS_ENDPOINT = f"{API_BASE_URL}/models"
CHAT_COMPLETIONS_ENDPOINT = f"{API_BASE_URL}/chat/completions"

# –ö–ª—é—á –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–ù–ï–ë–ï–ó–û–ü–ê–°–ù–û –≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–¥–µ)
DEFAULT_API_KEY = "sk_MyidbhnT9jXzw-YDymhijjY8NF15O0Qy7C36etNTAxE"

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ 429 (Rate Limit)
MAX_RETRIES = 3

st.set_page_config(page_title="üß† Novita AI Batch Processor", layout="wide")

#######################################
# 2) –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
#######################################

def custom_postprocess_text(text: str) -> str:
    """
    –§—É–Ω–∫—Ü–∏—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞:
    1. –£–¥–∞–ª—è–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å "Note:".
    2. –£–¥–∞–ª—è–µ—Ç –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ "fucking", "explicit" –∏ "intense", –µ—Å–ª–∏ –æ–Ω–∏ –ø–æ—è–≤–ª—è—é—Ç—Å—è –≤ –Ω–∞—á–∞–ª–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
    3. –ó–∞–º–µ–Ω—è–µ—Ç —Ü–µ–Ω–∑—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ "F***" –Ω–∞ "fuck".
    4. –£–¥–∞–ª—è–µ—Ç –∫–∏—Ç–∞–π—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã.
    5. –£–¥–∞–ª—è–µ—Ç —ç–º–æ–¥–∑–∏.
    6. –£–±–∏—Ä–∞–µ—Ç –≤—Å–µ –¥–≤–æ–π–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã.
    """
    # 1. –£–¥–∞–ª—è–µ–º –ª—é–±—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å "Note:"
    text = re.sub(r'\s*Note:.*', '', text, flags=re.IGNORECASE)
    # 2. –£–¥–∞–ª—è–µ–º –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –≤ –Ω–∞—á–∞–ª–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
    pattern_sentence = re.compile(r'(^|(?<=[.!?]\s))\s*(?:fucking|explicit|intense)[\s,:\-]+', flags=re.IGNORECASE)
    text = pattern_sentence.sub(r'\1', text)
    # 3. –ó–∞–º–µ–Ω—è–µ–º "F***" –Ω–∞ "fuck"
    text = re.sub(r'\bF\*+\b', 'fuck', text, flags=re.IGNORECASE)
    # 4. –£–¥–∞–ª—è–µ–º –∫–∏—Ç–∞–π—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
    text = re.sub(r'[\u4e00-\u9fff]+', '', text)
    # 5. –£–¥–∞–ª—è–µ–º —ç–º–æ–¥–∑–∏
    emoji_pattern = re.compile("["
                               u"\U0001F600-\U0001F64F"
                               u"\U0001F300-\U0001F5FF"
                               u"\U0001F680-\U0001F6FF"
                               u"\U0001F1E0-\U0001F1FF"
                               "]+", flags=re.UNICODE)
    text = emoji_pattern.sub(r'', text)
    # 6. –£–±–∏—Ä–∞–µ–º –¥–≤–æ–π–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    text = text.replace('"', '')
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def get_model_list(api_key: str):
    """–ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ API Novita AI"""
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    try:
        resp = requests.get(LIST_MODELS_ENDPOINT, headers=headers)
        if resp.status_code == 200:
            data = resp.json()
            models = [m["id"] for m in data.get("data", [])]
            return models
        else:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π. –ö–æ–¥: {resp.status_code}. –¢–µ–∫—Å—Ç: {resp.text}")
            return []
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
        return []

def chat_completion_request(
    api_key: str,
    messages: list,
    model: str,
    max_tokens: int,
    temperature: float,
    top_p: float,
    min_p: float,
    top_k: int,
    presence_penalty: float,
    frequency_penalty: float,
    repetition_penalty: float
):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π chat-–∫–æ–º–ø–ª–∏—à–Ω —Å retries –ø—Ä–∏ 429."""
    payload = {
        "model": model,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": temperature,
        "top_p": top_p,
        "top_k": top_k,
        "presence_penalty": presence_penalty,
        "frequency_penalty": frequency_penalty,
        "repetition_penalty": repetition_penalty,
        "min_p": min_p
    }
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    attempts = 0
    while attempts < MAX_RETRIES:
        attempts += 1
        try:
            resp = requests.post(CHAT_COMPLETIONS_ENDPOINT, headers=headers, data=json.dumps(payload))
            if resp.status_code == 200:
                data = resp.json()
                return data["choices"][0]["message"].get("content", "")
            elif resp.status_code == 429:
                time.sleep(2)
                continue
            else:
                return f"–û—à–∏–±–∫–∞: {resp.status_code} - {resp.text}"
        except Exception as e:
            return f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}"
    return "–û—à–∏–±–∫–∞: –ü—Ä–µ–≤—ã—à–µ–Ω–æ —á–∏—Å–ª–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ 429 RATE_LIMIT."

def process_single_row(
    api_key: str,
    model: str,
    system_prompt: str,
    user_prompt: str,
    row_text: str,
    max_tokens: int,
    temperature: float,
    top_p: float,
    min_p: float,
    top_k: int,
    presence_penalty: float,
    frequency_penalty: float,
    repetition_penalty: float
):
    """–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."""
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"{user_prompt}\n{row_text}"}
    ]
    raw_response = chat_completion_request(
        api_key,
        messages,
        model,
        max_tokens,
        temperature,
        top_p,
        min_p,
        top_k,
        presence_penalty,
        frequency_penalty,
        repetition_penalty
    )
    final_response = custom_postprocess_text(raw_response)
    return final_response

def process_file(
    api_key: str,
    model: str,
    system_prompt: str,
    user_prompt: str,
    df: pd.DataFrame,
    title_col: str,
    response_format: str,
    max_tokens: int,
    temperature: float,
    top_p: float,
    min_p: float,
    top_k: int,
    presence_penalty: float,
    frequency_penalty: float,
    repetition_penalty: float,
    chunk_size: int = 10,
    max_workers: int = 5
):
    """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –ø–æ—Å—Ç—Ä–æ—á–Ω–æ –±–µ–∑ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è."""
    results = []
    total_rows = len(df)
    for start_idx in range(0, total_rows, chunk_size):
        end_idx = min(start_idx + chunk_size, total_rows)
        chunk_indices = list(df.index[start_idx:end_idx])
        chunk_results = [None] * len(chunk_indices)
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_i = {}
            for i, row_idx in enumerate(chunk_indices):
                row_text = str(df.loc[row_idx, title_col])
                future = executor.submit(
                    process_single_row,
                    api_key,
                    model,
                    system_prompt,
                    user_prompt,
                    row_text,
                    max_tokens,
                    temperature,
                    top_p,
                    min_p,
                    top_k,
                    presence_penalty,
                    frequency_penalty,
                    repetition_penalty
                )
                future_to_i[future] = i
            for future in concurrent.futures.as_completed(future_to_i):
                i = future_to_i[future]
                chunk_results[i] = future.result()
        results.extend(chunk_results)
    df_out = df.copy()
    df_out["rewrite"] = results
    return df_out

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞, –ª–æ–≥–∏–∫–∞ –±–µ–∑ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è) ---

def translate_completion_request(
    api_key: str,
    messages: list,
    model: str,
    max_tokens: int,
    temperature: float,
    top_p: float,
    min_p: float,
    top_k: int,
    presence_penalty: float,
    frequency_penalty: float,
    repetition_penalty: float
):
    raw_response = chat_completion_request(
        api_key,
        messages,
        model,
        max_tokens,
        temperature,
        top_p,
        min_p,
        top_k,
        presence_penalty,
        frequency_penalty,
        repetition_penalty
    )
    final_response = custom_postprocess_text(raw_response)
    return final_response

def process_translation_single_row(
    api_key: str,
    model: str,
    system_prompt: str,
    user_prompt: str,
    row_text: str,
    max_tokens: int,
    temperature: float,
    top_p: float,
    min_p: float,
    top_k: int,
    presence_penalty: float,
    frequency_penalty: float,
    repetition_penalty: float
):
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"{user_prompt}\n{row_text}"}
    ]
    translated_text = translate_completion_request(
        api_key=api_key,
        messages=messages,
        model=model,
        max_tokens=max_tokens,
        temperature=temperature,
        top_p=top_p,
        min_p=min_p,
        top_k=top_k,
        presence_penalty=presence_penalty,
        frequency_penalty=frequency_penalty,
        repetition_penalty=repetition_penalty
    )
    return translated_text

def process_translation_file(
    api_key: str,
    model: str,
    system_prompt: str,
    user_prompt: str,
    df: pd.DataFrame,
    title_col: str,
    max_tokens: int,
    temperature: float,
    top_p: float,
    min_p: float,
    top_k: int,
    presence_penalty: float,
    frequency_penalty: float,
    repetition_penalty: float,
    chunk_size: int = 10,
    max_workers: int = 5
):
    results = []
    total_rows = len(df)
    for start_idx in range(0, total_rows, chunk_size):
        end_idx = min(start_idx + chunk_size, total_rows)
        chunk_indices = list(df.index[start_idx:end_idx])
        chunk_results = [None] * len(chunk_indices)
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_i = {}
            for i, row_idx in enumerate(chunk_indices):
                row_text = str(df.loc[row_idx, title_col])
                future = executor.submit(
                    process_translation_single_row,
                    api_key,
                    model,
                    system_prompt,
                    user_prompt,
                    row_text,
                    max_tokens,
                    temperature,
                    top_p,
                    min_p,
                    top_k,
                    presence_penalty,
                    frequency_penalty,
                    repetition_penalty
                )
                future_to_i[future] = i
            for future in concurrent.futures.as_completed(future_to_i):
                i = future_to_i[future]
                chunk_results[i] = future.result()
        results.extend(chunk_results)
    df_out = df.copy()
    df_out["translated_title"] = results
    return df_out

# --- –ù–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ —Å —É–¥–∞–ª–µ–Ω–∏–µ–º –≤—Ä–µ–¥–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ ---
def clean_text(text: str, harmful_patterns: list) -> str:
    """
    –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ —É–¥–∞–ª—è–µ—Ç –µ–≥–æ –≤—Ö–æ–∂–¥–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞.
    """
    for pattern in harmful_patterns:
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã, —á—Ç–æ–±—ã –∏—Å–∫–∞—Ç—å –±—É–∫–≤–∞–ª—å–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (–±–µ–∑ —É—á–µ—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞)
        text = re.sub(re.escape(pattern), "", text, flags=re.IGNORECASE)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def process_postprocessing_file(df: pd.DataFrame, text_col: str, harmful_patterns: list):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç DataFrame, –ø—Ä–∏–º–µ–Ω—è—è –æ—á–∏—Å—Ç–∫—É —Ç–µ–∫—Å—Ç–∞ –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º."""
    cleaned_texts = df[text_col].astype(str).apply(lambda txt: clean_text(txt, harmful_patterns))
    df_out = df.copy()
    df_out["cleaned"] = cleaned_texts
    return df_out

#######################################
# 3) –ü–†–ï–°–ï–¢–´ –ú–û–î–ï–õ–ï–ô
#######################################

PRESETS = {
    "Default": {
        "system_prompt": "Act like you are a helpful assistant.",
        "max_tokens": 512,
        "temperature": 0.70,
        "top_p": 1.0,
        "min_p": 0.0,
        "top_k": 40,
        "presence_penalty": 0.0,
        "frequency_penalty": 0.0,
        "repetition_penalty": 1.0
    },
    "NSFW": {
        "system_prompt": "You are an advanced NSFW content rewriter and evaluator. Generate one vivid and explicit title based on the input, ensuring it stays within 90 characters. The title should align with NSFW standards, SEO relevance, and native fluency.",
        "max_tokens": 32000,
        "temperature": 0.70,
        "top_p": 1.0,
        "min_p": 0.0,
        "top_k": 40,
        "presence_penalty": 0.20,
        "frequency_penalty": 0.40,
        "repetition_penalty": 1.22
    },
    "Adult_Content_Generator": {
        "system_prompt": "You are a professional content creator specializing in adult NSFW content. Generate creative and engaging content based on the input provided.",
        "max_tokens": 2500,
        "temperature": 0.85,
        "top_p": 0.95,
        "min_p": 0.0,
        "top_k": 50,
        "presence_penalty": 0.30,
        "frequency_penalty": 0.50,
        "repetition_penalty": 1.50
    },
    "Erotic_Story_Teller": {
        "system_prompt": "You are an expert in writing erotic stories. Generate a captivating and tasteful story based on the input provided.",
        "max_tokens": 5000,
        "temperature": 0.75,
        "top_p": 0.90,
        "min_p": 0.0,
        "top_k": 60,
        "presence_penalty": 0.25,
        "frequency_penalty": 0.35,
        "repetition_penalty": 1.30
    }
}

#######################################
# 4) –ò–ù–¢–ï–†–§–ï–ô–°
#######################################

st.title("üß† Novita AI Batch Processor")

# –ü–æ–ª–µ –≤–≤–æ–¥–∞ API Key
st.sidebar.header("üîë –ù–∞—Å—Ç—Ä–æ–π–∫–∏ API")
api_key = st.sidebar.text_input("API Key", value=DEFAULT_API_KEY, type="password")

# –°–æ–∑–¥–∞–µ–º 4 –≤–∫–ª–∞–¥–∫–∏: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞, –ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞, –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞, –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
tabs = st.tabs(["üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞", "üåê –ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞", "üìÇ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞", "üßπ –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞"])

########################################
# –í–∫–ª–∞–¥–∫–∞ 1: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
########################################
with tabs[0]:
    st.header("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞")

    with st.expander("üé® –í—ã–±–æ—Ä –ø—Ä–µ—Å–µ—Ç–∞ –º–æ–¥–µ–ª–∏", expanded=True):
        preset_names = list(PRESETS.keys())
        selected_preset = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–µ—Å–µ—Ç", preset_names, index=0)
        preset = PRESETS[selected_preset]
        system_prompt_text = preset["system_prompt"]
        max_tokens_text = preset["max_tokens"]
        temperature_text = preset["temperature"]
        top_p_text = preset["top_p"]
        min_p_text = preset["min_p"]
        top_k_text = preset["top_k"]
        presence_penalty_text = preset["presence_penalty"]
        frequency_penalty_text = preset["frequency_penalty"]
        repetition_penalty_text = preset["repetition_penalty"]
        if st.button("–°–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–µ—Å–µ—Ç–∞", key="reset_preset_text"):
            selected_preset = "Default"
            preset = PRESETS[selected_preset]
            system_prompt_text = preset["system_prompt"]
            max_tokens_text = preset["max_tokens"]
            temperature_text = preset["temperature"]
            top_p_text = preset["top_p"]
            min_p_text = preset["min_p"]
            top_k_text = preset["top_k"]
            presence_penalty_text = preset["presence_penalty"]
            frequency_penalty_text = preset["frequency_penalty"]
            repetition_penalty_text = preset["repetition_penalty"]

    st.markdown("---")
    left_col, right_col = st.columns(2)
    with left_col:
        st.subheader("üìö –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞")
        st.caption("–°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–∑ API Novita AI")
        if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π (–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞)", key="refresh_models_text"):
            if not api_key:
                st.error("‚ùå –ö–ª—é—á API –ø—É—Å—Ç")
                st.session_state["model_list_text"] = []
            else:
                model_list_text = get_model_list(api_key)
                st.session_state["model_list_text"] = model_list_text
        if "model_list_text" not in st.session_state:
            st.session_state["model_list_text"] = []
        if st.session_state["model_list_text"]:
            selected_model_text = st.selectbox("‚úÖ –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å", st.session_state["model_list_text"], key="select_model_text")
        else:
            selected_model_text = st.selectbox("‚úÖ –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å", ["meta-llama/llama-3.1-8b-instruct", "Nous-Hermes-2-Mixtral-8x7B-DPO"], key="select_model_default_text")
    with right_col:
        with st.expander("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", expanded=True):
            st.subheader("‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
            system_prompt_text = st.text_area("üìù System Prompt", value=system_prompt_text, key="system_prompt_text")
            max_tokens_text = st.slider("üî¢ max_tokens", min_value=0, max_value=64000, value=max_tokens_text, step=1, key="max_tokens_text")
            temperature_text = st.slider("üå°Ô∏è temperature", min_value=0.0, max_value=2.0, value=temperature_text, step=0.01, key="temperature_text")
            top_p_text = st.slider("üìä top_p", min_value=0.0, max_value=1.0, value=top_p_text, step=0.01, key="top_p_text")
            min_p_text = st.slider("üìâ min_p", min_value=0.0, max_value=1.0, value=min_p_text, step=0.01, key="min_p_text")
            top_k_text = st.slider("üîù top_k", min_value=0, max_value=100, value=top_k_text, step=1, key="top_k_text")
            presence_penalty_text = st.slider("‚öñÔ∏è presence_penalty", min_value=0.0, max_value=2.0, value=presence_penalty_text, step=0.01, key="presence_penalty_text")
            frequency_penalty_text = st.slider("üìâ frequency_penalty", min_value=0.0, max_value=2.0, value=frequency_penalty_text, step=0.01, key="frequency_penalty_text")
            repetition_penalty_text = st.slider("üîÅ repetition_penalty", min_value=0.0, max_value=2.0, value=repetition_penalty_text, step=0.01, key="repetition_penalty_text")

    st.subheader("üìù –û–¥–∏–Ω–æ—á–Ω—ã–π –ø—Ä–æ–º–ø—Ç")
    user_prompt_single_text = st.text_area("–í–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", key="user_prompt_single_text")
    if st.button("üöÄ –û—Ç–ø—Ä–∞–≤–∏—Ç—å –æ–¥–∏–Ω–æ—á–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞)", key="submit_single_text"):
        if not api_key:
            st.error("‚ùå API Key –Ω–µ —É–∫–∞–∑–∞–Ω!")
        elif not user_prompt_single_text.strip():
            st.error("‚ùå –ü—Ä–æ–º–ø—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º!")
        else:
            messages = [
                {"role": "system", "content": system_prompt_text},
                {"role": "user", "content": user_prompt_single_text}
            ]
            raw_response = chat_completion_request(
                api_key=api_key,
                messages=messages,
                model=selected_model_text,
                max_tokens=max_tokens_text,
                temperature=temperature_text,
                top_p=top_p_text,
                min_p=min_p_text,
                top_k=top_k_text,
                presence_penalty=presence_penalty_text,
                frequency_penalty=frequency_penalty_text,
                repetition_penalty=repetition_penalty_text
            )
            final_response = custom_postprocess_text(raw_response)
            st.success("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—É—á–µ–Ω!")
            st.text_area("üìÑ –û—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏", value=final_response, height=200)

    st.markdown("---")
    st.subheader("üìÇ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞")
    user_prompt_text = st.text_area("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –∫ –∑–∞–≥–æ–ª–æ–≤–∫—É)", key="user_prompt_text")
    st.markdown("##### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ TXT/CSV")
    with st.expander("üìë –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ñ–∞–π–ª–∞", expanded=True):
        delimiter_input_text = st.text_input("üî∏ –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å (delimiter)", value="|", key="delimiter_input_text")
        column_input_text = st.text_input("üî∏ –ù–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)", value="id,title", key="column_input_text")
    uploaded_file_text = st.file_uploader("üì§ –ü—Ä–∏–∫—Ä–µ–ø–∏—Ç—å —Ñ–∞–π–ª (CSV –∏–ª–∏ TXT, –¥–æ 100000 —Å—Ç—Ä–æ–∫)", type=["csv", "txt"], key="uploaded_file_text")
    df_text = None
    if uploaded_file_text is not None:
        file_extension = uploaded_file_text.name.split(".")[-1].lower()
        try:
            if file_extension == "csv":
                df_text = pd.read_csv(uploaded_file_text)
            else:
                content = uploaded_file_text.read().decode("utf-8")
                lines = content.splitlines()
                columns = [c.strip() for c in column_input_text.split(",")]
                parsed_lines = []
                for line in lines:
                    splitted = line.split(delimiter_input_text, maxsplit=len(columns) - 1)
                    if len(splitted) < len(columns):
                        splitted += [""] * (len(columns) - len(splitted))
                    parsed_lines.append(splitted)
                df_text = pd.DataFrame(parsed_lines, columns=columns)
            st.write("### üìã –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Ñ–∞–π–ª–∞")
            num_preview = st.number_input("üîç –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞", min_value=1, max_value=100, value=10)
            st.dataframe(df_text.head(num_preview))
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
            df_text = None
    if df_text is not None:
        cols_text = df_text.columns.tolist()
        with st.expander("üìÇ –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫ —Ñ–∞–π–ª–∞", expanded=True):
            title_col_text = st.selectbox("üìå –ö–∞–∫–∞—è –∫–æ–ª–æ–Ω–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–º?", cols_text, key="title_col_text")
            max_workers_text = st.slider("üîÑ –ü–æ—Ç–æ–∫–∏ (max_workers)", min_value=1, max_value=20, value=5, key="max_workers_text")
        if st.button("‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–∞ (–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞)", key="process_file_text"):
            if not api_key:
                st.error("‚ùå API Key –Ω–µ —É–∫–∞–∑–∞–Ω!")
            else:
                df_out_text = process_file(
                    api_key=api_key,
                    model=selected_model_text,
                    system_prompt=system_prompt_text,
                    user_prompt=user_prompt_text,
                    df=df_text,
                    title_col=title_col_text,
                    response_format="csv",
                    max_tokens=max_tokens_text,
                    temperature=temperature_text,
                    top_p=top_p_text,
                    min_p=min_p_text,
                    top_k=top_k_text,
                    presence_penalty=presence_penalty_text,
                    frequency_penalty=frequency_penalty_text,
                    repetition_penalty=repetition_penalty_text,
                    chunk_size=10,
                    max_workers=max_workers_text
                )
                st.success("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                output_format = st.selectbox("üì• –§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞", ["csv", "txt"], key="output_format_text")
                if output_format == "csv":
                    csv_out_text = df_out_text.to_csv(index=False).encode("utf-8")
                    st.download_button("üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç (CSV)", data=csv_out_text, file_name="result.csv", mime="text/csv")
                else:
                    txt_out_text = df_out_text.to_csv(index=False, sep="|", header=False).encode("utf-8")
                    st.download_button("üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç (TXT)", data=txt_out_text, file_name="result.txt", mime="text/plain")

########################################
# –í–∫–ª–∞–¥–∫–∞ 2: –ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞
########################################
with tabs[1]:
    st.header("üåê –ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞")
    with st.expander("üé® –í—ã–±–æ—Ä –ø—Ä–µ—Å–µ—Ç–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞", expanded=True):
        preset_names_translate = list(PRESETS.keys())
        selected_preset_translate = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–µ—Å–µ—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞", preset_names_translate, index=0)
        preset_translate = PRESETS[selected_preset_translate]
        system_prompt_translate = preset_translate["system_prompt"]
        max_tokens_translate = preset_translate["max_tokens"]
        temperature_translate = preset_translate["temperature"]
        top_p_translate = preset_translate["top_p"]
        min_p_translate = preset_translate["min_p"]
        top_k_translate = preset_translate["top_k"]
        presence_penalty_translate = preset_translate["presence_penalty"]
        frequency_penalty_translate = preset_translate["frequency_penalty"]
        repetition_penalty_translate = preset_translate["repetition_penalty"]
        if st.button("–°–±—Ä–æ—Å–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–µ—Å–µ—Ç–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞", key="reset_preset_translate"):
            selected_preset_translate = "Default"
            preset_translate = PRESETS[selected_preset_translate]
            system_prompt_translate = preset_translate["system_prompt"]
            max_tokens_translate = preset_translate["max_tokens"]
            temperature_translate = preset_translate["temperature"]
            top_p_translate = preset_translate["top_p"]
            min_p_translate = preset_translate["min_p"]
            top_k_translate = preset_translate["top_k"]
            presence_penalty_translate = preset_translate["presence_penalty"]
            frequency_penalty_translate = preset_translate["frequency_penalty"]
            repetition_penalty_translate = preset_translate["repetition_penalty"]
    st.markdown("---")
    left_col_trans, right_col_trans = st.columns(2)
    with left_col_trans:
        st.subheader("üìö –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞")
        st.caption("–°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–∑ API Novita AI")
        if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π (–ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞)", key="refresh_models_translate"):
            if not api_key:
                st.error("‚ùå –ö–ª—é—á API –ø—É—Å—Ç")
                st.session_state["model_list_translate"] = []
            else:
                model_list_translate = get_model_list(api_key)
                st.session_state["model_list_translate"] = model_list_translate
        if "model_list_translate" not in st.session_state:
            st.session_state["model_list_translate"] = []
        if st.session_state["model_list_translate"]:
            selected_model_translate = st.selectbox("‚úÖ –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å", st.session_state["model_list_translate"], key="select_model_translate")
        else:
            selected_model_translate = st.selectbox("‚úÖ –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å", ["meta-llama/llama-3.1-8b-instruct", "Nous-Hermes-2-Mixtral-8x7B-DPO"], key="select_model_default_translate")
    with right_col_trans:
        with st.expander("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞", expanded=True):
            st.subheader("‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞")
            translate_output_format = st.selectbox("üì• –§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ –ø–µ—Ä–µ–≤–æ–¥–∞", ["csv", "txt"], key="translate_output_format")
            system_prompt_translate = st.text_area("üìù System Prompt –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞", value=system_prompt_translate, key="system_prompt_translate")
            max_tokens_translate = st.slider("üî¢ max_tokens (–ø–µ—Ä–µ–≤–æ–¥)", min_value=0, max_value=64000, value=max_tokens_translate, step=1, key="max_tokens_translate")
            temperature_translate = st.slider("üå°Ô∏è temperature (–ø–µ—Ä–µ–≤–æ–¥)", min_value=0.0, max_value=2.0, value=temperature_translate, step=0.01, key="temperature_translate")
            top_p_translate = st.slider("üìä top_p (–ø–µ—Ä–µ–≤–æ–¥)", min_value=0.0, max_value=1.0, value=top_p_translate, step=0.01, key="top_p_translate")
            min_p_translate = st.slider("üìâ min_p (–ø–µ—Ä–µ–≤–æ–¥)", min_value=0.0, max_value=1.0, value=min_p_translate, step=0.01, key="min_p_translate")
            top_k_translate = st.slider("üîù top_k (–ø–µ—Ä–µ–≤–æ–¥)", min_value=0, max_value=100, value=top_k_translate, step=1, key="top_k_translate")
            presence_penalty_translate = st.slider("‚öñÔ∏è presence_penalty (–ø–µ—Ä–µ–≤–æ–¥)", min_value=0.0, max_value=2.0, value=presence_penalty_translate, step=0.01, key="presence_penalty_translate")
            frequency_penalty_translate = st.slider("üìâ frequency_penalty (–ø–µ—Ä–µ–≤–æ–¥)", min_value=0.0, max_value=2.0, value=frequency_penalty_translate, step=0.01, key="frequency_penalty_translate")
            repetition_penalty_translate = st.slider("üîÅ repetition_penalty (–ø–µ—Ä–µ–≤–æ–¥)", min_value=0.0, max_value=2.0, value=repetition_penalty_translate, step=0.01, key="repetition_penalty_translate")
    st.markdown("---")
    st.subheader("üìù –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∞")
    languages = ["English", "Chinese", "Japanese", "Hindi"]
    source_language = st.selectbox("üî† –ò—Å—Ö–æ–¥–Ω—ã–π —è–∑—ã–∫", languages, index=0, key="source_language")
    target_language = st.selectbox("üî° –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫", languages, index=1, key="target_language")
    if source_language == target_language:
        st.warning("‚ö†Ô∏è –ò—Å—Ö–æ–¥–Ω—ã–π –∏ —Ü–µ–ª–µ–≤–æ–π —è–∑—ã–∫–∏ –¥–æ–ª–∂–Ω—ã –æ—Ç–ª–∏—á–∞—Ç—å—Å—è!")
    st.markdown("---")
    st.subheader("üìÇ –ü–µ—Ä–µ–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞")
    with st.expander("üìë –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ñ–∞–π–ª–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞", expanded=True):
        delimiter_input_translate = st.text_input("üî∏ –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å (delimiter) –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞", value="|", key="delimiter_input_translate")
        column_input_translate = st.text_input("üî∏ –ù–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é) –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞", value="id,title", key="column_input_translate")
    uploaded_file_translate = st.file_uploader("üì§ –ü—Ä–∏–∫—Ä–µ–ø–∏—Ç—å —Ñ–∞–π–ª –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ (CSV –∏–ª–∏ TXT, –¥–æ 100000 —Å—Ç—Ä–æ–∫)", type=["csv", "txt"], key="uploaded_file_translate")
    df_translate = None
    if uploaded_file_translate is not None:
        file_extension_translate = uploaded_file_translate.name.split(".")[-1].lower()
        try:
            if file_extension_translate == "csv":
                df_translate = pd.read_csv(uploaded_file_translate)
            else:
                content_translate = uploaded_file_translate.read().decode("utf-8")
                lines_translate = content_translate.splitlines()
                columns_translate = [c.strip() for c in column_input_translate.split(",")]
                parsed_lines_translate = []
                for line in lines_translate:
                    splitted_translate = line.split(delimiter_input_translate, maxsplit=len(columns_translate) - 1)
                    if len(splitted_translate) < len(columns_translate):
                        splitted_translate += [""] * (len(columns_translate) - len(splitted_translate))
                    parsed_lines_translate.append(splitted_translate)
                df_translate = pd.DataFrame(parsed_lines_translate, columns=columns_translate)
            st.write("### üìã –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Ñ–∞–π–ª–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞")
            num_preview_translate = st.number_input("üîç –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞", min_value=1, max_value=100, value=10, key="num_preview_translate")
            st.dataframe(df_translate.head(num_preview_translate))
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
            df_translate = None
    if df_translate is not None:
        cols_translate = df_translate.columns.tolist()
        with st.expander("üìÇ –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫ —Ñ–∞–π–ª–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞", expanded=True):
            id_col_translate = st.selectbox("üÜî –ö–∞–∫–∞—è –∫–æ–ª–æ–Ω–∫–∞ —è–≤–ª—è–µ—Ç—Å—è ID?", cols_translate, key="id_col_translate")
            title_col_translate = st.selectbox("üìå –ö–∞–∫–∞—è –∫–æ–ª–æ–Ω–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–º –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞?", cols_translate, key="title_col_translate")
            max_workers_translate = st.slider("üîÑ –ü–æ—Ç–æ–∫–∏ (max_workers) –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞", min_value=1, max_value=20, value=5, key="max_workers_translate")
        if st.button("‚ñ∂Ô∏è –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥", key="start_translation"):
            if not api_key:
                st.error("‚ùå API Key –Ω–µ —É–∫–∞–∑–∞–Ω!")
            elif source_language == target_language:
                st.error("‚ùå –ò—Å—Ö–æ–¥–Ω—ã–π –∏ —Ü–µ–ª–µ–≤–æ–π —è–∑—ã–∫–∏ –¥–æ–ª–∂–Ω—ã –æ—Ç–ª–∏—á–∞—Ç—å—Å—è!")
            elif not title_col_translate:
                st.error("‚ùå –ù–µ –≤—ã–±—Ä–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞!")
            else:
                user_prompt_translate = f"Translate the following text from {source_language} to {target_language}:"
                df_translated = process_translation_file(
                    api_key=api_key,
                    model=selected_model_translate,
                    system_prompt=system_prompt_translate,
                    user_prompt=user_prompt_translate,
                    df=df_translate,
                    title_col=title_col_translate,
                    max_tokens=max_tokens_translate,
                    temperature=temperature_translate,
                    top_p=top_p_translate,
                    min_p=min_p_translate,
                    top_k=top_k_translate,
                    presence_penalty=presence_penalty_translate,
                    frequency_penalty=frequency_penalty_translate,
                    repetition_penalty=repetition_penalty_translate,
                    chunk_size=10,
                    max_workers=max_workers_translate
                )
                st.success("‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
                if translate_output_format == "csv":
                    csv_translated = df_translated.to_csv(index=False).encode("utf-8")
                    st.download_button("üì• –°–∫–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª (CSV)", data=csv_translated, file_name="translated_result.csv", mime="text/csv")
                else:
                    txt_translated = df_translated.to_csv(index=False, sep="|", header=False).encode("utf-8")
                    st.download_button("üì• –°–∫–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª (TXT)", data=txt_translated, file_name="translated_result.txt", mime="text/plain")

########################################
# –í–∫–ª–∞–¥–∫–∞ 3: –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
########################################
with tabs[2]:
    st.header("üìÇ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞")
    st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª (CSV –∏–ª–∏ TXT) –∏ —É–∫–∞–∂–∏—Ç–µ, –Ω–∞ —Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –Ω—É–∂–Ω–æ —Ä–∞–∑–±–∏—Ç—å —Ñ–∞–π–ª.")
    split_size = st.number_input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –Ω–∞ —á–∞—Å—Ç—å", min_value=1, value=5000, step=100)
    uploaded_file_split = st.file_uploader("üì§ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è", type=["csv", "txt"], key="uploaded_file_split")
    if uploaded_file_split is not None:
        file_extension_split = uploaded_file_split.name.split(".")[-1].lower()
        try:
            if file_extension_split == "csv":
                df_split = pd.read_csv(uploaded_file_split)
                total_rows = len(df_split)
                st.write(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: {total_rows}")
                num_parts = math.ceil(total_rows / split_size)
                st.write(f"–§–∞–π–ª –±—É–¥–µ—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {num_parts} —á–∞—Å—Ç–µ–π.")
                for i in range(num_parts):
                    part_df = df_split.iloc[i*split_size:(i+1)*split_size]
                    csv_part = part_df.to_csv(index=False).encode("utf-8")
                    st.download_button(
                        label=f"–°–∫–∞—á–∞—Ç—å —á–∞—Å—Ç—å {i+1} (CSV)",
                        data=csv_part,
                        file_name=f"part_{i+1}.csv",
                        mime="text/csv"
                    )
            else:
                content = uploaded_file_split.read().decode("utf-8")
                lines = content.splitlines()
                total_lines = len(lines)
                st.write(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: {total_lines}")
                num_parts = math.ceil(total_lines / split_size)
                st.write(f"–§–∞–π–ª –±—É–¥–µ—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {num_parts} —á–∞—Å—Ç–µ–π.")
                for i in range(num_parts):
                    part_lines = lines[i*split_size:(i+1)*split_size]
                    part_content = "\n".join(part_lines)
                    st.download_button(
                        label=f"–°–∫–∞—á–∞—Ç—å —á–∞—Å—Ç—å {i+1} (TXT)",
                        data=part_content.encode("utf-8"),
                        file_name=f"part_{i+1}.txt",
                        mime="text/plain"
                    )
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")

########################################
# –í–∫–ª–∞–¥–∫–∞ 4: –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
########################################
with tabs[3]:
    st.header("üßπ –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞")
    st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª (CSV –∏–ª–∏ TXT) –∏ –∑–∞–¥–∞–π—Ç–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–¥–∞–ª–∏—Ç—å –∏–∑ —Ç–µ–∫—Å—Ç–∞.")
    default_patterns = """Intense Deep Ass Fucking Session with Alex Greene and Brendan Patrick - Icon Male
Intense Black-on-Black Sauna Sex: Micah Brandt and Sean Zevran Heat Up the Hot House
Explicit Threesome Adventures: Clay Towers & Hans Berlin Heat Up Pride Studios
Explicit Anal Encounter: Hot Mess with Justin Brody & Boomer Banks from Cocky Boys"""
    harmful_patterns_input = st.text_area("–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (–ø–æ –æ–¥–Ω–æ–º—É –≤ —Å—Ç—Ä–æ–∫–µ)", value=default_patterns, height=150)
    harmful_patterns = [line.strip() for line in harmful_patterns_input.splitlines() if line.strip()]
    uploaded_file_post = st.file_uploader("üì§ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏ (CSV –∏–ª–∏ TXT)", type=["csv", "txt"], key="uploaded_file_post")
    if uploaded_file_post is not None:
        file_extension_post = uploaded_file_post.name.split(".")[-1].lower()
        if file_extension_post == "csv":
            try:
                df_post = pd.read_csv(uploaded_file_post)
                st.write("### üìã –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Ñ–∞–π–ª–∞")
                st.dataframe(df_post.head(10))
                cols_post = df_post.columns.tolist()
                text_col = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –æ—á–∏—Å—Ç–∫–∏", cols_post, key="text_col_post")
                if st.button("‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫—É (CSV)", key="process_post_csv"):
                    df_cleaned = process_postprocessing_file(df_post, text_col, harmful_patterns)
                    st.success("‚úÖ –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                    csv_cleaned = df_cleaned.to_csv(index=False).encode("utf-8")
                    st.download_button("üì• –°–∫–∞—á–∞—Ç—å –æ—á–∏—â–µ–Ω–Ω—ã–π —Ñ–∞–π–ª (CSV)", data=csv_cleaned, file_name="cleaned_result.csv", mime="text/csv")
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ CSV: {e}")
        else:
            try:
                content_post = uploaded_file_post.read().decode("utf-8")
                lines_post = content_post.splitlines()
                st.write(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(lines_post)}")
                # –û—á–∏—â–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
                cleaned_lines = [clean_text(line, harmful_patterns) for line in lines_post]
                cleaned_content = "\n".join(cleaned_lines)
                st.text_area("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞", value=cleaned_content[:1000], height=200)
                st.download_button("üì• –°–∫–∞—á–∞—Ç—å –æ—á–∏—â–µ–Ω–Ω—ã–π —Ñ–∞–π–ª (TXT)", data=cleaned_content.encode("utf-8"), file_name="cleaned_result.txt", mime="text/plain")
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ TXT: {e}")

